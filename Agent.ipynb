{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac97064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c258972",
   "metadata": {},
   "source": [
    "## Importing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96b51b",
   "metadata": {},
   "source": [
    "First, we import the ML tool which loads various models and property finders to report the computational labels for seven properties for MOFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5f27e",
   "metadata": {},
   "source": [
    "Input: CSD Ref Code <br/>Output: dictionary of key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a3f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML Tools\n",
    "from ml.pipeline import full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3f7df",
   "metadata": {},
   "source": [
    "Next we will import the Graph RAG tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7950cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GraphRAG Tool\n",
    "from agent.GraphTool.GraphRetriever import query_mof_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967ea944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [query_mof_database, full_pipeline]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34793297",
   "metadata": {},
   "source": [
    "## Importing Main Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a1c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_my_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7887d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_my_agent(tools=tools,use_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e8499",
   "metadata": {},
   "source": [
    "## Setting up Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6e9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac95c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run to start a new chat\n",
    "thread_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1db174",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config to manage chat sessions\n",
    "config = {\"configurable\": {\"thread_id\": str(thread_id)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5265c4",
   "metadata": {},
   "source": [
    "## Mini Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb33dbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e6962870ae445fbf01f94b863ea8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<div style=\"text-align: center;\"><h3>ChemGraph QA</h3></div>'), HBox(children=(Text‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from langchain_core.messages import BaseMessage, AIMessage, ToolMessage, HumanMessage\n",
    "from IPython.display import display, HTML\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def mock_agent_invoke(user_input):\n",
    "    return agent.invoke({\"messages\": [{\"role\":\"user\", \"content\":user_input}]}, config)\n",
    "\n",
    "# --- MESSAGE FORMATTING ---\n",
    "def format_message(message: BaseMessage) -> str:\n",
    "    \"\"\"\n",
    "    Converts a LangChain message object into a styled HTML string.\n",
    "    \"\"\"\n",
    "    style = {\n",
    "        \"shared\": \"padding: 10px; border-radius: 8px; margin-bottom: 10px; max-width: 80%; display: block;\",\n",
    "        \"human\": \"background-color: #E6F3FF; color: #003366; margin-left: auto;\",\n",
    "        \"ai\": \"background-color: #F0F0F0; color: #333; margin-right: auto;\",\n",
    "        \"tool_call\": \"background-color: #FFFBE6; border: 1px solid #FFD633; font-family: monospace; font-size: 0.9em;\",\n",
    "        \"tool_result\": \"background-color: #E6FFFA; border: 1px solid #33FFC2; font-family: monospace; font-size: 0.9em;\"\n",
    "    }\n",
    "    \n",
    "    if isinstance(message, HumanMessage):\n",
    "        return f'<div style=\"{style[\"shared\"]} {style[\"human\"]}\">üë§ <strong>You:</strong><br>{message.content}</div>'\n",
    "    \n",
    "    elif isinstance(message, AIMessage):\n",
    "        content_html = f\"ü§ñ <strong>AI:</strong><br>{message.content}\" if message.content else \"ü§ñ <strong>AI:</strong>\"\n",
    "        \n",
    "        tool_html = \"\"\n",
    "        if message.tool_calls:\n",
    "            for tool in message.tool_calls:\n",
    "                tool_html += f\"\"\"\n",
    "                <div style=\"{style['shared']} {style['ai']} {style['tool_call']}\">\n",
    "                    <strong>üõ†Ô∏è Tool Call: </strong><code>{tool['name']}</code>\n",
    "                    <pre style=\"margin-top: 5px; white-space: pre-wrap; word-wrap: break-word;\">{tool['args']}</pre>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        return f'<div style=\"{style[\"shared\"]} {style[\"ai\"]}\">{content_html}</div>{tool_html}'\n",
    "\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        return f\"\"\"\n",
    "        <div style=\"{style['shared']} {style['ai']} {style['tool_result']}\">\n",
    "            <strong>‚öôÔ∏è Tool Result (ID: <code>{message.tool_call_id}</code>):</strong>\n",
    "            <pre style=\"margin-top: 5px; white-space: pre-wrap; word-wrap: break-word;\">{message.content}</pre>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return f\"<p><strong>{type(message).__name__}:</strong> {message.content}</p>\"\n",
    "\n",
    "\n",
    "# --- WIDGETS SETUP ---\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Type your message and press Enter...',\n",
    "    layout={'width': 'calc(100% - 100px)'}\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='info',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "\n",
    "# Use an HTML widget for the conversation display to render formatted messages\n",
    "conversation_display = widgets.HTML(\n",
    "    value=\"\",\n",
    "    layout={'border': '1px solid #ccc', 'padding': '15px', 'height': '400px', 'overflow_y': 'auto'}\n",
    ")\n",
    "\n",
    "# --- CONVERSATION STATE & EVENT HANDLER ---\n",
    "\n",
    "def handle_submit(sender: Any):\n",
    "    user_input = text_input.value\n",
    "    if not user_input:\n",
    "        return\n",
    "\n",
    "    # For better UX, temporarily append the user's message and a thinking indicator.\n",
    "    # This will be completely replaced by the full history from the agent.\n",
    "    user_message_html = format_message(HumanMessage(content=user_input))\n",
    "    thinking_indicator = f'<div style=\"text-align: center; color: #888;\">ü§ñ Thinking...</div>'\n",
    "    conversation_display.value += user_message_html + thinking_indicator\n",
    "    \n",
    "    text_input.value = \"\"\n",
    "\n",
    "    # --- THIS IS WHERE YOU CALL YOUR AGENT ---\n",
    "    # Your real agent call would look something like:\n",
    "    # final_state = agent.invoke({'messages': [HumanMessage(content=user_input)]})\n",
    "    final_state = mock_agent_invoke(user_input)\n",
    "    \n",
    "    # The agent returns the ENTIRE history, so we use it to completely redraw the chat.\n",
    "    conversation_history = final_state['messages']\n",
    "    \n",
    "    # Re-render the entire conversation using the definitive history from the agent.\n",
    "    conversation_display.value = \"\".join(format_message(msg) for msg in conversation_history)\n",
    "\n",
    "\n",
    "# Link handlers to events\n",
    "submit_button.on_click(handle_submit)\n",
    "text_input.on_submit(handle_submit)\n",
    "\n",
    "# --- LAYOUT & DISPLAY ---\n",
    "input_box = widgets.HBox([text_input, submit_button])\n",
    "chat_ui = widgets.VBox([\n",
    "    widgets.HTML('<div style=\"text-align: center;\"><h3>ChemGraph QA</h3></div>'),\n",
    "    input_box,\n",
    "    conversation_display\n",
    "])\n",
    "\n",
    "display(chat_ui)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f41a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
